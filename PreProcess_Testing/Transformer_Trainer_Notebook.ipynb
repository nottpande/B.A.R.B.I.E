{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FOwRggVcwtzP"
   },
   "outputs": [],
   "source": [
    "from transformer import Transformer # this is the transformer.py file\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6TApzOj5xCwR"
   },
   "outputs": [],
   "source": [
    "english_file = '../Data/english.txt' # replace this path with appropriate one\n",
    "kannada_file = '../Data/kannada.txt' # replace this path with appropriate one\n",
    "\n",
    "# Generated this by filtering Appendix code\n",
    "\n",
    "START_TOKEN = '<START>'\n",
    "PADDING_TOKEN = '<PADDING>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "kannada_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ', \n",
    "                      'ँ', 'ఆ', 'ఇ', 'ా', 'ి', 'ీ', 'ు', 'ూ', \n",
    "                      'ಅ', 'ಆ', 'ಇ', 'ಈ', 'ಉ', 'ಊ', 'ಋ', 'ೠ', 'ಌ', 'ಎ', 'ಏ', 'ಐ', 'ಒ', 'ಓ', 'ಔ', \n",
    "                      'ಕ', 'ಖ', 'ಗ', 'ಘ', 'ಙ', \n",
    "                      'ಚ', 'ಛ', 'ಜ', 'ಝ', 'ಞ', \n",
    "                      'ಟ', 'ಠ', 'ಡ', 'ಢ', 'ಣ', \n",
    "                      'ತ', 'ಥ', 'ದ', 'ಧ', 'ನ', \n",
    "                      'ಪ', 'ಫ', 'ಬ', 'ಭ', 'ಮ', \n",
    "                      'ಯ', 'ರ', 'ಱ', 'ಲ', 'ಳ', 'ವ', 'ಶ', 'ಷ', 'ಸ', 'ಹ', \n",
    "                      '಼', 'ಽ', 'ಾ', 'ಿ', 'ೀ', 'ು', 'ೂ', 'ೃ', 'ೄ', 'ೆ', 'ೇ', 'ೈ', 'ೊ', 'ೋ', 'ೌ', '್', 'ೕ', 'ೖ', 'ೞ', 'ೣ', 'ಂ', 'ಃ', \n",
    "                      '೦', '೧', '೨', '೩', '೪', '೫', '೬', '೭', '೮', '೯', PADDING_TOKEN, END_TOKEN]\n",
    "\n",
    "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                        ':', '<', '=', '>', '?', '@',\n",
    "                        '[', '\\\\', ']', '^', '_', '`', \n",
    "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
    "                        'y', 'z', \n",
    "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gA8ESmCrNoc7"
   },
   "outputs": [],
   "source": [
    "index_to_kannada = {k:v for k,v in enumerate(kannada_vocabulary)}\n",
    "kannada_to_index = {v:k for k,v in enumerate(kannada_vocabulary)}\n",
    "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
    "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9SYGjRdoxRg-"
   },
   "outputs": [],
   "source": [
    "with open(english_file, 'r') as file:\n",
    "    english_sentences = file.readlines()\n",
    "with open(kannada_file, 'r') as file:\n",
    "    kannada_sentences = file.readlines()\n",
    "\n",
    "# Limit Number of sentences\n",
    "TOTAL_SENTENCES = 200000\n",
    "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
    "kannada_sentences = kannada_sentences[:TOTAL_SENTENCES]\n",
    "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]\n",
    "kannada_sentences = [sentence.rstrip('\\n') for sentence in kannada_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUB-BkgFxXfM",
    "outputId": "bcf7e19c-d1df-4b69-bdfa-eb74ac1a4338"
   },
   "outputs": [],
   "source": [
    "english_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OT-aznAxc5U",
    "outputId": "716c4145-fdc2-4bb0-e883-c3dcad30c2da"
   },
   "outputs": [],
   "source": [
    "kannada_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8VAutsTxlaR",
    "outputId": "ff8fba72-020d-4f0c-b3c5-31c102b6fe9b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "PERCENTILE = 97\n",
    "print( f\"{PERCENTILE}th percentile length Kannada: {np.percentile([len(x) for x in kannada_sentences], PERCENTILE)}\" )\n",
    "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HG9ezqvaxl4b",
    "outputId": "d13be774-ca07-4333-856e-76186f71caae"
   },
   "outputs": [],
   "source": [
    "max_sequence_length = 200\n",
    "\n",
    "def is_valid_tokens(sentence, vocab):\n",
    "    for token in list(set(sentence)):\n",
    "        if token not in vocab:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_valid_length(sentence, max_sequence_length):\n",
    "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
    "\n",
    "valid_sentence_indicies = []\n",
    "for index in range(len(kannada_sentences)):\n",
    "    kannada_sentence, english_sentence = kannada_sentences[index], english_sentences[index]\n",
    "    if is_valid_length(kannada_sentence, max_sequence_length) \\\n",
    "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
    "      and is_valid_tokens(kannada_sentence, kannada_vocabulary):\n",
    "        valid_sentence_indicies.append(index)\n",
    "\n",
    "print(f\"Number of sentences: {len(kannada_sentences)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "o80QDn4CxsV7"
   },
   "outputs": [],
   "source": [
    "kannada_sentences = [kannada_sentences[i] for i in valid_sentence_indicies]\n",
    "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35xhLztQiLIQ",
    "outputId": "aa70ad04-2e45-4c78-c852-61e92c51a96a"
   },
   "outputs": [],
   "source": [
    "kannada_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqOFnclmyxAE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "d_model = 512\n",
    "batch_size = 30\n",
    "ffn_hidden = 2048\n",
    "num_heads = 8\n",
    "drop_prob = 0.1\n",
    "num_layers = 1\n",
    "max_sequence_length = 200\n",
    "kn_vocab_size = len(kannada_vocabulary)\n",
    "\n",
    "transformer = Transformer(d_model, \n",
    "                          ffn_hidden,\n",
    "                          num_heads, \n",
    "                          drop_prob, \n",
    "                          num_layers, \n",
    "                          max_sequence_length,\n",
    "                          kn_vocab_size,\n",
    "                          english_to_index,\n",
    "                          kannada_to_index,\n",
    "                          START_TOKEN, \n",
    "                          END_TOKEN, \n",
    "                          PADDING_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zc2hYQk9yxX0",
    "outputId": "c060f588-6a2e-4179-9475-5acafd641f1f"
   },
   "outputs": [],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asUJX-STy7fg"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, english_sentences, kannada_sentences):\n",
    "        self.english_sentences = english_sentences\n",
    "        self.kannada_sentences = kannada_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.english_sentences[idx], self.kannada_sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-auNWjkdzDge"
   },
   "outputs": [],
   "source": [
    "dataset = TextDataset(english_sentences, kannada_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "roH2A4m4zF4z",
    "outputId": "f4353aa8-2f37-43b6-be0f-12aab9a35145"
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGeHNlzozIGF",
    "outputId": "ec3596fe-feee-426c-dce8-373fb07080fd"
   },
   "outputs": [],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YDttjQ0zMrv"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EnjHKB1zM8Y",
    "outputId": "1a825e56-6706-46ee-85b5-ed7f0ac657fb"
   },
   "outputs": [],
   "source": [
    "for batch_num, batch in enumerate(iterator):\n",
    "    print(batch)\n",
    "    if batch_num > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnanjzqtzQi8"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(ignore_index=kannada_to_index[PADDING_TOKEN],\n",
    "                                reduction='none')\n",
    "\n",
    "# When computing the loss, we are ignoring cases when the label is the padding token\n",
    "for params in transformer.parameters():\n",
    "    if params.dim() > 1:\n",
    "        nn.init.xavier_uniform_(params)\n",
    "\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_saWU5QmVem2"
   },
   "outputs": [],
   "source": [
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(eng_batch, kn_batch):\n",
    "    num_sentences = len(eng_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "      eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
    "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
    "      kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
    "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
    "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdgtTSKvwN9_"
   },
   "source": [
    "Modify mask such that the padding tokens cannot look ahead.\n",
    "In Encoder, tokens before it should be -1e9 while tokens after it should be -inf.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLcXI4wkMLck"
   },
   "source": [
    "Note the target mask starts with 2 rows of non masked items: https://github.com/SamLynnEvans/Transformer/blob/master/Beam.py#L55\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ju59VDGLuOqf",
    "outputId": "0ad34e31-521a-4ca2-f444-26b5374946f6"
   },
   "outputs": [],
   "source": [
    "transformer.train()\n",
    "transformer.to(device)\n",
    "total_loss = 0\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    iterator = iter(train_loader)\n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        transformer.train()\n",
    "        eng_batch, kn_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, kn_batch)\n",
    "        optim.zero_grad()\n",
    "        kn_predictions = transformer(eng_batch,\n",
    "                                     kn_batch,\n",
    "                                     encoder_self_attention_mask.to(device), \n",
    "                                     decoder_self_attention_mask.to(device), \n",
    "                                     decoder_cross_attention_mask.to(device),\n",
    "                                     enc_start_token=False,\n",
    "                                     enc_end_token=False,\n",
    "                                     dec_start_token=True,\n",
    "                                     dec_end_token=True)\n",
    "        labels = transformer.decoder.sentence_embedding.batch_tokenize(kn_batch, start_token=False, end_token=True)\n",
    "        loss = criterian(\n",
    "            kn_predictions.view(-1, kn_vocab_size).to(device),\n",
    "            labels.view(-1).to(device)\n",
    "        ).to(device)\n",
    "        valid_indicies = torch.where(labels.view(-1) == kannada_to_index[PADDING_TOKEN], False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #train_losses.append(loss.item())\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
    "            print(f\"English: {eng_batch[0]}\")\n",
    "            print(f\"Kannada Translation: {kn_batch[0]}\")\n",
    "            kn_sentence_predicted = torch.argmax(kn_predictions[0], axis=1)\n",
    "            predicted_sentence = \"\"\n",
    "            for idx in kn_sentence_predicted:\n",
    "              if idx == kannada_to_index[END_TOKEN]:\n",
    "                break\n",
    "              predicted_sentence += index_to_kannada[idx.item()]\n",
    "            print(f\"Kannada Prediction: {predicted_sentence}\")\n",
    "\n",
    "\n",
    "            transformer.eval()\n",
    "            kn_sentence = (\"\",)\n",
    "            eng_sentence = (\"should we go to the mall?\",)\n",
    "            for word_counter in range(max_sequence_length):\n",
    "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, kn_sentence)\n",
    "                predictions = transformer(eng_sentence,\n",
    "                                          kn_sentence,\n",
    "                                          encoder_self_attention_mask.to(device), \n",
    "                                          decoder_self_attention_mask.to(device), \n",
    "                                          decoder_cross_attention_mask.to(device),\n",
    "                                          enc_start_token=False,\n",
    "                                          enc_end_token=False,\n",
    "                                          dec_start_token=True,\n",
    "                                          dec_end_token=False)\n",
    "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
    "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "                next_token = index_to_kannada[next_token_index]\n",
    "                kn_sentence = (kn_sentence[0] + next_token, )\n",
    "                if next_token == END_TOKEN:\n",
    "                  break\n",
    "            \n",
    "            print(f\"Evaluation translation (should we go to the mall?) : {kn_sentence}\")\n",
    "            print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model state\n",
    "print(\"Saving Model\")\n",
    "torch.save(transformer.state_dict(), \"../Models/transformer_model.pth\")\n",
    "print(\"Model Saved Successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nosVPGVijId"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOQe-juylBiJ"
   },
   "outputs": [],
   "source": [
    "transformer.eval()\n",
    "def translate(eng_sentence):\n",
    "  eng_sentence = (eng_sentence,)\n",
    "  kn_sentence = (\"\",)\n",
    "  for word_counter in range(max_sequence_length):\n",
    "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, kn_sentence)\n",
    "    predictions = transformer(eng_sentence,\n",
    "                              kn_sentence,\n",
    "                              encoder_self_attention_mask.to(device), \n",
    "                              decoder_self_attention_mask.to(device), \n",
    "                              decoder_cross_attention_mask.to(device),\n",
    "                              enc_start_token=False,\n",
    "                              enc_end_token=False,\n",
    "                              dec_start_token=True,\n",
    "                              dec_end_token=False)\n",
    "    next_token_prob_distribution = predictions[0][word_counter]\n",
    "    next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "    next_token = index_to_kannada[next_token_index]\n",
    "    kn_sentence = (kn_sentence[0] + next_token, )\n",
    "    if next_token == END_TOKEN:\n",
    "      break\n",
    "  return kn_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDVH_YsxlK6q",
    "outputId": "83c47f99-53c0-4c2d-c26a-aaa426f50563"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"what should we do when the day starts?\")\n",
    "print(translation)\n",
    "#ದಿನ ಪ್ರಾರಂಭವಾದಾಗ ನಾವು ಏನು ಮಾಡಬೇಕು?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9yfawBnul0W",
    "outputId": "d9e6e6b7-683b-45f9-f013-c53c31038306"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"how is this the truth?\")\n",
    "print(translation)\n",
    "#ಇದು ಹೇಗೆ ಸತ್ಯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpdYBk5-urcQ",
    "outputId": "ca7249c5-efda-4f41-f052-ecef9691be82"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"the world is a large place with different people\")\n",
    "print(translation)\n",
    "#ಪ್ರಪಂಚವು ವಿಭಿನ್ನ ಜನರೊಂದಿಗೆ ದೊಡ್ಡ ಸ್ಥಳವಾಗಿದೆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ni9e2UYUuxi3",
    "outputId": "b93968e6-3f12-4794-b277-3a3821af221e"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"my name is ajay\")\n",
    "print(translation)\n",
    "#ನನ್ನ ಹೆಸರು ಅಜಯ್"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJuJKHqFldW3",
    "outputId": "71aa2c6c-ec77-4b02-d39b-bd724012fb53"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"i cannot stand this smell\")\n",
    "print(translation)\n",
    "#ನಾನು ಈ ವಾಸನೆಯನ್ನು ಸಹಿಸುವುದಿಲ್ಲ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxHC4Lirlfu8",
    "outputId": "5a3ca401-abac-41af-d9db-99fb7a57fe00"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"noodles are the best\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLVOSI0Oli16",
    "outputId": "9f9445a1-2802-4688-900c-d7ecf2bd5c35"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"why care about this?\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MStWCoAt0Ixp"
   },
   "source": [
    "This translated pretty well : \"What is the reason. Why\" without punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AB6TEJfGlkRT",
    "outputId": "adb465d5-b0ed-4be4-9251-62c079f49491"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"this is the best thing ever\")\n",
    "print(translation)\n",
    "# ಇದು ಎಂದೆಂದಿಗೂ ಉತ್ತಮವಾಗಿದೆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxsUjSybxYkh"
   },
   "source": [
    "The translation : \"This is very unusual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQwDbuWBlmmA",
    "outputId": "7ae0e2c0-02c0-4c74-bc47-26b67da55a06"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"i am here\")\n",
    "print(translation)\n",
    "# ನಾನು ಇಲ್ಲಿದ್ದೇನೆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmyZ2-I6x0Yf"
   },
   "source": [
    "Translation: \"I have heard\". \n",
    "This is why word based translator may perform better than character translator. This is actually very good at optimizing the objective of the current transformer even though the translation is off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ifeV4bGluIj",
    "outputId": "6bce922d-d0db-432c-e6c6-97d482f1dea6"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"click this\")\n",
    "print(translation)\n",
    "# ಇದನ್ನು ಕ್ಲಿಕ್ ಮಾಡಿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RB5DUBEl1kD",
    "outputId": "9109e504-8b9e-45dc-e13c-e878b3741e4e"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"where is the mall?\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdeJ9CvMn5LM",
    "outputId": "044b5dac-29a9-4b60-e66a-4e10739a9756"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"what should we do?\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoikFnov1rj-"
   },
   "source": [
    "This is correct; but it absolutely fumbles on the next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7GFeyzrg1fIZ",
    "outputId": "2b4dfb04-def2-4725-9e76-5476bf85e2ef"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"today, what should we do\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0upygLS-sXcO",
    "outputId": "53a62435-ab16-4d4c-8a9f-0bf07af2a501"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"why did they activate?\")\n",
    "print(translation)\n",
    "# ಅವರು ಏಕೆ ಸಕ್ರಿಯಗೊಳಿಸಿದರು?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSrsqEGmtcl2",
    "outputId": "1b8b8faa-5370-426a-f2f2-fe852696bf7a"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"why did they do this?\")\n",
    "print(translation)\n",
    "# ಅವರು ಇದನ್ನು ಏಕೆ ಮಾಡಿದರು?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7ISM5rd3BLJ"
   },
   "source": [
    "That turned out well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjTcH2HFtyld",
    "outputId": "9dea5498-f139-4cbd-ee8c-6108e1b92fc4"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"i am well.\")\n",
    "print(translation)\n",
    "# ನಾನು ಆರಾಮವಾಗಿದ್ದೇನೆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cP0YX2g74eP7"
   },
   "source": [
    "Translation: \"I will give you something\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pGdN13kt5Br",
    "outputId": "240256c5-f594-41b0-8218-2c70a22a156f"
   },
   "outputs": [],
   "source": [
    "translation = translate(\"whats the word on the street?\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFYZ6pOe4o-X"
   },
   "source": [
    "Kind of close semantically. Translation is something like: \"What is this about\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzrOcNUk1-e5"
   },
   "source": [
    "## Insights\n",
    "\n",
    "- When training, we can treat every alphabet as a single unit instead of splitting it into it's corresponding parts to preserve meaning. For example, ಮಾ should be 1 unit when comuting a loss. It should not be decomposed into ಮ + ఆ\n",
    "- Using word-based or BPE based tokenizations may help mitigate (1). Also, we will get valid word (or BPE) units if we do so. \n",
    "- Make sure the training set has a large variety of sentences that are not just about one topic like \"work\" and \"government\"\n",
    "- Increase the number of encoder / decoder units for better translations. It was set to the minimum of 1 of each unit here.\n",
    "- Create a translator with a language you understand ideally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd6_k0Uu5V7f"
   },
   "source": [
    "Overall, this model definately learned something. And you can use other languages instead of this kannada language and might see better luck"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "BARBIE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
